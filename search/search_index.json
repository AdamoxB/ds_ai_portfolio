{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home Page","text":""},{"location":"#project_from-the-world-of-data-and-artificial-intelligence","title":"Project_from the world of data and artificial intelligence","text":""},{"location":"#introduction","title":"Introduction","text":"<p>Welcome to the page dedicated to projects in data analysis, machine learning, and artificial intelligence. Here you\u2019ll find projects I\u2019ve been working on recently.</p> <p>Feel free to explore\u2014hope you discover something interesting here!</p>"},{"location":"#my-short-story","title":"My short story","text":"<p>In 2011, I earned a Master of Science in Engineering from the Faculty of Electrical Engineering at Warsaw University of Technology. My studies ignited my interest in new technologies.</p> <p>For the past ten years, I have been gaining experience in the lighting industry, working as a lighting systems designer at two different companies. During this time, I significantly developed my skills in automating design processes. Previously, I held the position of senior product manager responsible for lighting systems. My career began after university, where I worked as an electrical network designer and successfully utilized AutoCAD.</p> <p>In 2025 I was inspired by the data industry, the role of Data Scientist, and the rapidly evolving field of artificial intelligence. An opportunity arose to further develop these skills by creating AI agents\u2014automation that is not deterministic but can adapt far better to various process\u2011automation tasks, thereby reducing verification time and increasing overall efficiency.</p>"},{"location":"#my-achievements","title":"My Achievements","text":""},{"location":"#certificate-of-completion","title":"Certificate of Completion","text":"<p>I'm proud to have completed this course!  </p> <p>Here's my certificate:</p> Certificate of Completion <p>You can download my certificate here: Certificate</p>"},{"location":"#contact","title":"Contact","text":"<p>Adam Biela email: bielaa3@gmail.com tel: +48 506 767 998</p>"},{"location":"index%20copy%202/","title":"Mermaid TEST","text":""},{"location":"index%20copy%202/#mermaid-test","title":"Mermaid TEST","text":"<p>```mermaid graph LR     A --&gt; B     B --&gt; C</p>"},{"location":"index%20copy%202/#mermaid-test_1","title":"Mermaid TEST","text":"<p>```mermaid flowchart LR     TEST1 --&gt; TEST2</p>"},{"location":"index%20copy%202/#project_from-the-world-of-data-and-artificial-intelligence","title":"Project_from the world of data and artificial intelligence","text":""},{"location":"index%20copy%202/#introduction","title":"Introduction","text":"<p>Welcome to the page dedicated to projects in data analysis, machine learning, and artificial intelligence. Here you\u2019ll find projects I\u2019ve been working on recently.</p> <p>Feel free to explore\u2014hope you discover something interesting here!</p>"},{"location":"index%20copy%202/#my-short-story","title":"My short story","text":"<p>In 2011, I earned a Master of Science in Engineering from the Faculty of Electrical Engineering at Warsaw University of Technology. My studies ignited my interest in new technologies.</p> <p>For the past ten years, I have been gaining experience in the lighting industry, working as a lighting systems designer at two different companies. During this time, I significantly developed my skills in automating design processes. Previously, I held the position of senior product manager responsible for lighting systems. My career began after university, where I worked as an electrical network designer and successfully utilized AutoCAD.</p> <p>In 2025 I was inspired by the data industry, the role of Data Scientist, and the rapidly evolving field of artificial intelligence. An opportunity arose to further develop these skills by creating AI agents\u2014automation that is not deterministic but can adapt far better to various process\u2011automation tasks, thereby reducing verification time and increasing overall efficiency.</p>"},{"location":"index%20copy%202/#my-achievements","title":"My Achievements","text":""},{"location":"index%20copy%202/#certificate-of-completion","title":"Certificate of Completion","text":"<p>I'm proud to have completed this course!  </p> <p>Here's my certificate:</p> Certificate of Completion <p>You can download my certificate here: Certificate</p>"},{"location":"index%20copy%202/#contact","title":"Contact","text":"<p>Adam Biela email: bielaa3@gmail.com tel: +48 506 767 998</p>"},{"location":"index%20copy/","title":"Mermaid TEST","text":""},{"location":"index%20copy/#mermaid-test","title":"Mermaid TEST","text":"<pre><code>graph LR\n    A --&gt; B\n    B --&gt; C\n\n\n\n\n# Mermaid TEST\n\n```mermaid\nflowchart LR\n    TEST1 --&gt; TEST2\n</code></pre>"},{"location":"index%20copy/#project_from-the-world-of-data-and-artificial-intelligence","title":"Project_from the world of data and artificial intelligence","text":""},{"location":"index%20copy/#introduction","title":"Introduction","text":"<p>Welcome to the page dedicated to projects in data analysis, machine learning, and artificial intelligence. Here you\u2019ll find projects I\u2019ve been working on recently.</p> <p>Feel free to explore\u2014hope you discover something interesting here!</p>"},{"location":"index%20copy/#my-short-story","title":"My short story","text":"<p>In 2011, I earned a Master of Science in Engineering from the Faculty of Electrical Engineering at Warsaw University of Technology. My studies ignited my interest in new technologies.</p> <p>For the past ten years, I have been gaining experience in the lighting industry, working as a lighting systems designer at two different companies. During this time, I significantly developed my skills in automating design processes. Previously, I held the position of senior product manager responsible for lighting systems. My career began after university, where I worked as an electrical network designer and successfully utilized AutoCAD.</p> <p>In 2025 I was inspired by the data industry, the role of Data Scientist, and the rapidly evolving field of artificial intelligence. An opportunity arose to further develop these skills by creating AI agents\u2014automation that is not deterministic but can adapt far better to various process\u2011automation tasks, thereby reducing verification time and increasing overall efficiency.</p>"},{"location":"index%20copy/#my-achievements","title":"My Achievements","text":""},{"location":"index%20copy/#certificate-of-completion","title":"Certificate of Completion","text":"<p>I'm proud to have completed this course!  </p> <p>Here's my certificate:</p> Certificate of Completion <p>You can download my certificate here: Certificate</p>"},{"location":"index%20copy/#contact","title":"Contact","text":"<p>Adam Biela email: bielaa3@gmail.com tel: +48 506 767 998</p>"},{"location":"AI_Data_Visualizer/","title":"AI_Data_Visualizer","text":""},{"location":"AI_Data_Visualizer/#ai_data_visualizer-visualise-your-verrbal-data-with-ai","title":"AI_Data_Visualizer - visualise your verrbal data with AI","text":"<p>Project start: 2025-11-21</p>"},{"location":"AI_Data_Visualizer/#overview","title":"Overview","text":"<p>A Streamlit-powered web app that allows users to generate data visualizations using natural language prompts, leveraging AI models like GPT-4.1-nano to automatically produce and execute Python plotting code.</p>"},{"location":"AI_Data_Visualizer/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Upload and manage custom CSV datasets</li> <li>Choose from predefined datasets (Movies, Housing, Cars)</li> <li>Describe desired visualization in plain English (e.g., \"Plot sales over time by region\")</li> <li>Automatically generate and execute Python code using AI</li> <li>Display both the generated plot and the underlying code</li> <li>Support for multiple AI models in close future with toggle selection</li> <li>Real-time visualization with error handling and feedback</li> </ul>"},{"location":"AI_Data_Visualizer/#technologies-skills","title":"Technologies &amp; skills","text":"<ul> <li>Python</li> <li>Streamlit (for the web interface)</li> <li>Pandas (data handling)</li> <li>Matplotlib (plotting)</li> <li>OpenAI API (via GPT-4.1-nano)</li> <li>dotenv (environment variables)</li> <li>Secure API key management via <code>.streamlit/secrets.toml</code></li> </ul>"},{"location":"AI_Data_Visualizer/#project-report","title":"Project Report","text":"<ul> <li>The app enables non-technical users to create data visualizations without writing code.</li> <li>It uses a prompt engineering pipeline: primers are applied to guide AI model outputs, ensuring consistent and valid code generation.</li> <li>The system includes error handling and user feedback (e.g., timeout warnings).</li> <li>Model selection allows flexibility, with GPT-4.1-nano as the default due to cost efficiency.</li> <li>Future enhancements could include model switching via Hugging Face, support for more plot types, and offline execution.</li> </ul>"},{"location":"AI_Data_Visualizer/#sample-photos","title":"Sample photos","text":"AI_Data_Visualizer_Main_Interface Dataset_Selection_Panel Generated_Plot_with_Code Model_Selection_and_Execution"},{"location":"AI_Data_Visualizer/#application-usage","title":"Application usage","text":"<ul> <li>Upload a CSV file (e.g., sales, survey, or experimental data)</li> <li>Describe what kind of chart or graph you want (e.g., \"Show average income by city with a bar chart\")</li> <li>Select the AI model (GPT-4.1-nano recommended for speed and cost)</li> <li>Click \"Go!\" to generate the visualization</li> <li>View the plot and inspect the generated Python code</li> <li>Use the tabs to explore raw dataset contents</li> </ul> <p>Go to the application</p>"},{"location":"AI_Data_Visualizer/index%20copy/","title":"Index copy","text":""},{"location":"AI_Data_Visualizer/index%20copy/#ai_data_visualizer-visualise-your-verrbal-data-with-ai","title":"AI_Data_Visualizer - visualise your verrbal data with AI","text":"<p>Project start: 2024-11-21</p>"},{"location":"AI_Data_Visualizer/index%20copy/#overview","title":"Overview","text":"<p>A Streamlit-powered web app that allows users to generate data visualizations using natural language prompts, leveraging AI models like GPT-4.1-nano to automatically produce and execute Python plotting code.</p>"},{"location":"AI_Data_Visualizer/index%20copy/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Upload and manage custom CSV datasets</li> <li>Choose from predefined datasets (Movies, Housing, Cars)</li> <li>Describe desired visualization in plain English (e.g., \"Plot sales over time by region\")</li> <li>Automatically generate and execute Python code using AI</li> <li>Display both the generated plot and the underlying code</li> <li>Support for multiple AI models in close future with toggle selection</li> <li>Real-time visualization with error handling and feedback</li> </ul>"},{"location":"AI_Data_Visualizer/index%20copy/#technologies-skills","title":"Technologies &amp; skills","text":"<ul> <li>Python</li> <li>Streamlit (for the web interface)</li> <li>Pandas (data handling)</li> <li>Matplotlib (plotting)</li> <li>OpenAI API (via GPT-4.1-nano)</li> <li>dotenv (environment variables)</li> </ul> <ul> <li>Secure API key management via <code>.streamlit/secrets.toml</code></li> </ul>"},{"location":"AI_Data_Visualizer/index%20copy/#project-report","title":"Project Report","text":"<ul> <li>The app enables non-technical users to create data visualizations without writing code.</li> <li>It uses a prompt engineering pipeline: primers are applied to guide AI model outputs, ensuring consistent and valid code generation.</li> <li>The system includes error handling and user feedback (e.g., timeout warnings).</li> <li>Model selection allows flexibility, with GPT-4.1-nano as the default due to cost efficiency.</li> <li>Future enhancements could include model switching via Hugging Face, support for more plot types, and offline execution.</li> </ul>"},{"location":"AI_Data_Visualizer/index%20copy/#sample-photos","title":"Sample photos","text":"AI_Data_Visualizer_Main_Interface Dataset_Selection_Panel Generated_Plot_with_Code Model_Selection_and_Execution"},{"location":"AI_Data_Visualizer/index%20copy/#application-usage","title":"Application usage","text":"<ul> <li>Upload a CSV file (e.g., sales, survey, or experimental data)</li> <li>Describe what kind of chart or graph you want (e.g., \"Show average income by city with a bar chart\")</li> <li>Select the AI model (GPT-4.1-nano recommended for speed and cost)</li> <li>Click \"Go!\" to generate the visualization</li> <li>View the plot and inspect the generated Python code</li> <li>Use the tabs to explore raw dataset contents</li> </ul> <p>Go to the application</p>"},{"location":"AI_Short_Crime_Story_Generator/","title":"Short Crime Story Generator \ud83d\udcd6","text":""},{"location":"AI_Short_Crime_Story_Generator/#short-crime-story-generator","title":"Short Crime Story Generator \ud83d\udcd6","text":"<p>Go to the application</p>"},{"location":"AI_Short_Crime_Story_Generator/#1-sequence-diagram-user-login-story-generation-flow","title":"\u2705 1. Sequence Diagram: User Login &amp; Story Generation Flow","text":"<p>This shows the key user flow \u2014 from login to generating a story.</p> <pre><code>sequenceDiagram\n    participant User\n    participant App\n    participant Database\n    participant OpenAI\n    participant AuthSystem\n\n    User-&gt;&gt;App: Clicks \"Login\" (via sidebar)\n    App-&gt;&gt;AuthSystem: Validate credentials\n    AuthSystem--&gt;&gt;App: Returns success/failure\n    alt Login successful\n        App-&gt;&gt;App: Set user session (email, language, subscription)\n        App-&gt;&gt;App: Load translations (languages.json)\n        User-&gt;&gt;App: Enters text in input box\n        App-&gt;&gt;App: Check usage limits (input/output tokens)\n        alt Free user\n            App-&gt;&gt;App: Validate monthly limits\n            User-&gt;&gt;App: Clicks \"Generate Story\"\n            App-&gt;&gt;App: Select next model (gpt-4.1-nano)\n            App-&gt;&gt;OpenAI: Send prompt to generate story\n            OpenAI--&gt;&gt;App: Returns generated story with usage data\n            App-&gt;&gt;Database: Log input/output tokens\n            App--&gt;&gt;User: Display story and download button\n        else Premium user\n            App-&gt;&gt;App: Allow full token usage\n            User-&gt;&gt;App: Clicks \"Generate Story\"\n            App-&gt;&gt;OpenAI: Send prompt to generate story\n            OpenAI--&gt;&gt;App: Returns generated story with usage data\n            App-&gt;&gt;Database: Log input/output tokens\n            App--&gt;&gt;User: Display story and download button\n    end\n    User-&gt;&gt;App: Clicks \"Logout\"\n    App-&gt;&gt;App: Clear session\n</code></pre>"},{"location":"AI_Short_Crime_Story_Generator/#2-component-diagram-application-architecture","title":"\u2705 2. Component Diagram: Application Architecture","text":"<p>This shows the modular components and their relationships.</p> <pre><code>componentDiagram\n    [Streamlit App] --&gt; [User Interface]\n    [User Interface] --&gt; [Authentication Layer]\n    [User Interface] --&gt; [Translation Manager]\n    [User Interface] --&gt; [Usage Limit Checker]\n    [User Interface] --&gt; [OpenAI API Client]\n    [User Interface] --&gt; [Database Layer (PostgreSQL)]\n    [Database Layer] --&gt; [usages table]\n    [Database Layer] --&gt; [user_profiles table]\n\n    [Authentication Layer] --&gt; [Google OAuth]\n    [Translation Manager] --&gt; [languages.json]\n    [OpenAI API Client] --&gt; [OpenAI API]\n    [Usage Limit Checker] --&gt; [FREE / PREMIUM limits]\n    [OpenAI API Client] --&gt; [Model Rotation (gpt-4.1-nano)]\n\n    note right of [User Interface]\n        Main entry point for users\n        Handles routing, UI, state management\n    end\n\n    note right of [Authentication Layer]\n        Manages login/logout and user session\n        Uses Google OAuth\n    end\n\n    note right of [Translation Manager]\n        Loads and switches between languages (en/pl)\n        Uses JSON config file\n    end\n\n    note right of [Usage Limit Checker]\n        Tracks monthly token usage\n        Blocks free users at 2500 input / 3000 output\n    end\n\n    note right of [OpenAI API Client]\n        Dynamically selects model (cycle through list)\n        Sends prompts and receives responses\n    end\n\n    note right of [Database Layer]\n        Stores user sessions, usage logs\n        Ensures audit trail and quota tracking\n    end\n</code></pre>"},{"location":"AI_Short_Crime_Story_Generator/#3-flowchart-approval-process-decision-logic-for-usage-limits","title":"\u2705 3. Flowchart: Approval Process (Decision Logic for Usage Limits)","text":"<p>This illustrates how the app decides whether to allow or block a story generation based on user type and usage.</p> <pre><code>flowchart TD\n    A[User logs in] --&gt; B{Is user logged in?}\n    B -- No --&gt; C[Redirect to login]\n    B -- Yes --&gt; D{Is user premium?}\n    D -- No --&gt; E[Check monthly input tokens]\n    E --&gt; F{\u2265 2500 input tokens?}\n    F -- Yes --&gt; G[Block request: Usage limit exceeded]\n    F -- No --&gt; H{\u2265 3000 output tokens?}\n    H -- Yes --&gt; I[Block request: Usage limit exceeded]\n    H -- No --&gt; J[Allow generation]\n    D -- Yes --&gt; K[Check monthly input/output tokens]\n    K --&gt; L{\u2265 100k input/output tokens?}\n    L -- Yes --&gt; M[Block request: Premium limit exceeded]\n    L -- No --&gt; J[Allow generation]\n\n    style A fill:#f9f,stroke:#333\n    style C fill:#f9f,stroke:#333\n    style D fill:#f9f,stroke:#333\n    style E fill:#cfc,stroke:#333\n    style F fill:#cfc,stroke:#333\n    style G fill:#f9f,stroke:#333\n    style H fill:#cfc,stroke:#333\n    style I fill:#f9f,stroke:#333\n    style J fill:#cfc,stroke:#333\n    style K fill:#cfc,stroke:#333\n    style L fill:#cfc,stroke:#333\n    style M fill:#f9f,stroke:#333\n\n    classDef default fill:#f9f,stroke:#333,stroke-width:2px;\n    classDef warning fill:#f9f,stroke:#333;\n    classDef allowed fill:#cfc,stroke:#333;\n</code></pre>"},{"location":"AI_Short_Crime_Story_Generator/#overview","title":"Overview","text":"<p>A Streamlit-powered storytelling generator that creates engaging, structured short stories using OpenAI's language models, with user authentication, usage tracking, and tiered access based on subscription level.</p>"},{"location":"AI_Short_Crime_Story_Generator/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Generates creative, structured short stories (with introduction, development, twist, and moral) from user-provided prompts</li> <li>Implements dynamic model rotation among multiple GPT models (e.g., <code>gpt-4o-mini</code>, <code>gpt-4.1-mini</code>)</li> <li>Tracks token usage per user and month with PostgreSQL</li> <li>Enforces usage limits: free users (1k input / 10k output tokens), premium users (10k input / 100k output tokens)</li> <li>Supports Google OAuth login and subscription management via <code>st_paywall</code></li> <li>Provides real-time usage statistics and current model tracking in sidebar</li> <li>Allows downloading generated stories as plain text files</li> </ul>"},{"location":"AI_Short_Crime_Story_Generator/#technologies-skills","title":"Technologies &amp; skills","text":"<ul> <li>Python</li> <li>Streamlit</li> <li>OpenAI API</li> </ul> <ul> <li>Create and deploy databases PostgreSQL on Ubuntu server https://cloud.digitalocean.com/droplets?i=0c32ac</li> <li>st_paywall (for user subscription management)</li> <li>Pandas (data handling)</li> <li>psycopg2 (PostgreSQL connector)</li> <li>itertools.cycle (for model rotation)</li> </ul>"},{"location":"AI_Short_Crime_Story_Generator/#project-report","title":"Project Report","text":"<ul> <li>Implemented token-based usage limits with monthly reset</li> <li>Integrated secure Google OAuth login and subscription tier detection</li> <li>Designed dynamic model selection to balance performance and cost</li> <li>Built robust error handling for unauthenticated users and usage overages</li> <li>Added real-time feedback via progress spinner and usage metrics</li> <li>Ensured data privacy by storing only necessary usage metadata</li> </ul>"},{"location":"AI_Short_Crime_Story_Generator/#sample-photos","title":"Sample photos","text":""},{"location":"AI_Short_Crime_Story_Generator/#application-usage","title":"Application usage","text":"<ul> <li>Enter a prompt in the text area </li> <li>Click \"Generate\" to create a story</li> <li>View the generated story with model used and download option</li> <li>Monitor token usage in the sidebar</li> <li>Upgrade to premium for higher limits</li> </ul> <p>Go to the application</p>"},{"location":"Analysis_of_Key_Variables_in_Data_Sets/","title":"Analysis_of_Key_Variables_in_Data_Sets","text":"<p>Go to the application</p>"},{"location":"Analysis_of_Key_Variables_in_Data_Sets/#overview","title":"Overview","text":"<p>Interactive Streamlit app that loads a user\u2011supplied dataset, automatically detects whether the target column is for classification or regression, and runs PyCaret experiments to compare models, visualize feature importance, confusion matrices, and ROC curves.</p>"},{"location":"Analysis_of_Key_Variables_in_Data_Sets/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Upload CSV/JSON/XLSX files with custom separator selection.</li> <li>Random sampling of a user\u2011defined percentage of the dataframe for training.</li> <li>Automatic detection of problem type (classification vs regression).</li> <li>Interactive tabs: random rows, missing data analysis, and model setup.</li> <li>PyCaret ClassificationExperiment or RegressionExperiment setup with options to ignore columns, balance classes, normalize, and transform features.</li> <li>Model comparison (compare_models) with selectable model sets.</li> <li>Generation of feature importance plots, confusion matrices, and ROC curves.</li> <li>Save and load pre\u2011generated plot images for later use.</li> </ul>"},{"location":"Analysis_of_Key_Variables_in_Data_Sets/#technologies-skills","title":"Technologies &amp; skills","text":"<ul> <li>Python 3.x</li> <li>Streamlit</li> <li>Pandas, NumPy</li> <li>PyCaret (classification, regression)</li> <li>Matplotlib, Seaborn</li> <li>Scikit\u2011learn metrics</li> </ul>"},{"location":"Analysis_of_Key_Variables_in_Data_Sets/#project-report","title":"Project Report","text":"<ul> <li>The app demonstrates end\u2011to\u2011end machine learning workflow: data ingestion \u2192 preprocessing \u2192 model training \u2192 evaluation.</li> <li>It is designed for non\u2011technical users to quickly assess which algorithm works best on their dataset.</li> </ul>"},{"location":"Analysis_of_Key_Variables_in_Data_Sets/#sample-photos","title":"Sample photos","text":"built\u2011in dataset you can load your own data in the initial setup preliminary data analysis detection of a problem and model comparison range Feature Importance Confusion Matrix ROC Curves"},{"location":"Analysis_of_Key_Variables_in_Data_Sets/#application-usage","title":"Application usage","text":"<ul> <li>Upload a dataset.</li> <li>Choose separator and target column.</li> <li>Inspect random rows and missing data.</li> <li>Run model comparison and view evaluation plots.</li> </ul>"},{"location":"Analysis_of_Key_Variables_in_Data_Sets/#go-to-the-application","title":"Go to the application","text":""},{"location":"Data_Explorer%E2%80%93PyCaret/","title":"Data_Explorer\u2013PyCaret","text":""},{"location":"Data_Explorer%E2%80%93PyCaret/#go-to-the-application","title":"Go to the application","text":""},{"location":"Data_Explorer%E2%80%93PyCaret/#overview","title":"Overview","text":"<p>A lightweight Streamlit app that lets users load built-in or custom datasets and generate interactive data profiling reports using PyCaret and ydata\u2011profiling.</p>"},{"location":"Data_Explorer%E2%80%93PyCaret/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Select a dataset from the list of built\u2011in PyCaret datasets via sidebar.</li> <li>Upload CSV / Excel files for analysis.</li> <li>Preview the first rows of the selected dataset.</li> <li>Generate an interactive profiling report with ydata\u2011profiling.</li> <li>Export the report as HTML or PDF (PDF conversion uses pdfkit/wkhtmltopdf).</li> <li>Dark themed UI and responsive layout.</li> </ul>"},{"location":"Data_Explorer%E2%80%93PyCaret/#technologies-skills","title":"Technologies &amp; skills","text":"<ul> <li>Python</li> <li>Streamlit</li> <li>Pandas</li> <li>PyCaret datasets</li> <li>ydata\u2011profiling</li> <li>streamlit\u2011pandas\u2011profiling</li> <li>pdfkit / wkhtmltopdf (optional)</li> </ul>"},{"location":"Data_Explorer%E2%80%93PyCaret/#project-report","title":"Project Report","text":"<ul> <li>Profiling report generation and export functionality.</li> <li>User-friendly interface for data exploration.</li> </ul>"},{"location":"Data_Explorer%E2%80%93PyCaret/#sample-photos","title":"Sample photos","text":""},{"location":"Data_Explorer%E2%80%93PyCaret/#application-usage","title":"Application usage","text":"<ul> <li>Use the sidebar to choose a dataset or upload your own file.</li> <li>Click \"Generate Profiling Report\" to view and download the report.</li> </ul>"},{"location":"Data_Explorer%E2%80%93PyCaret/#go-to-the-application_1","title":"Go to the application","text":""},{"location":"Gapmind_Data_Dashboard/","title":"Gapmind_Data_Dashboard","text":""},{"location":"Gapmind_Data_Dashboard/#go-to-the-application","title":"Go to the application","text":""},{"location":"Gapmind_Data_Dashboard/#overview","title":"Overview","text":"<p>Interactive dashboard that visualizes the Gapminder dataset using Streamlit and Plotly Express.</p>"},{"location":"Gapmind_Data_Dashboard/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Year selector slider to choose the analysis year.</li> <li>Continent multiselect filter for country selection.</li> <li>X\u2011axis and Y\u2011axis metric selectors for scatter plots.</li> <li>Toggle for logarithmic scaling of the X\u2011axis.</li> <li>Country multiselect for time\u2011series line charts.</li> <li>Reset filters button to restore defaults.</li> <li>Scatter plot visualizing GDP per capita, life expectancy, or population across continents.</li> <li>Line chart showing selected metrics over time for chosen countries.</li> <li>Bar chart displaying top\u202fN countries by a chosen metric in the selected year.</li> <li>World choropleth map coloring countries by the selected metric.</li> <li>Data table view of the filtered dataset with CSV download capability.</li> </ul>"},{"location":"Gapmind_Data_Dashboard/#technologies-skills","title":"Technologies &amp; skills","text":"<ul> <li>Python</li> <li>Streamlit</li> <li>Plotly Express</li> <li>Pandas</li> </ul>"},{"location":"Gapmind_Data_Dashboard/#sample-photos","title":"Sample photos","text":"Gapminder Scatter Plot Gapminder Line Chart Gapminder Bar Chart"},{"location":"Gapmind_Data_Dashboard/#go-to-the-application_1","title":"Go to the application","text":""},{"location":"My_Chat_GPT/","title":"My Chat GPT","text":""},{"location":"My_Chat_GPT/#go-to-the-application","title":"Go to the application","text":""},{"location":"My_Chat_GPT/#overview","title":"Overview","text":"<p>A Streamlit web application that provides an interactive chat interface with OpenAI GPT models, supporting memory management, cost tracking, and persistent conversation storage.</p>"},{"location":"My_Chat_GPT/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Interactive chat interface using Streamlit.  </li> <li>Selection of conversation memory size to control context length.  </li> <li>Choice of GPT model from a predefined set with pricing.  </li> <li>Role selection for the chatbot (assistant, developer, system).  </li> <li>Persistent storage of conversations as JSON files on local disk.  </li> <li>Customizable chatbot personality via text area.  </li> <li>Real\u2011time cost calculation in USD and PLN based on token usage.  </li> <li>Display of current USD/PLN exchange rate fetched from an API.  </li> <li>Ability to create new conversations or switch between existing ones.  </li> <li>Help section with step\u2011by\u2011step tips for using ChatGPT to build Python programs.</li> </ul>"},{"location":"My_Chat_GPT/#technologies-skills","title":"Technologies &amp; skills","text":"<ul> <li>Python  </li> <li>Streamlit  </li> <li>OpenAI API (openai library)  </li> <li>dotenv  </li> <li>requests  </li> <li>pathlib / json  </li> </ul>"},{"location":"My_Chat_GPT/#project-report","title":"Project Report","text":"<ul> <li>Completed functional chat application with persistent storage and cost tracking.</li> </ul>"},{"location":"My_Chat_GPT/#sample-photos","title":"Sample photos","text":"Two ways of entering API_KEY Model_chose Chat_role Chat memory &amp; Tips"},{"location":"My_Chat_GPT/#application-usage","title":"Application usage","text":"<ul> <li>Open the Streamlit app in a browser.    </li> <li>Configure conversation memory, model, and role in the sidebar.  </li> <li>Enter prompts into the chat input to interact with GPT.  </li> <li>Monitor cost metrics (USD/PLN) on the sidebar.  </li> <li>Manage conversations: rename, create new, load existing.</li> </ul>"},{"location":"My_Chat_GPT/#where-to-get-api-key-and-addresses","title":"Where to get API key and addresses?","text":"<ol> <li>OpenAI API Key (openai_api_key): </li> <li>Visit the OpenAI API Keys page.  </li> <li>Log in to your account or create a new one.  </li> <li>Click \"Create API key\" and copy the key.</li> </ol>"},{"location":"My_Chat_GPT/#example-configuration-file","title":"Example configuration file:","text":"<pre><code>OPENAI_API_KEY=your-openai-api-key\n</code></pre>"},{"location":"My_Chat_GPT/#go-to-the-application_1","title":"Go to the application","text":""},{"location":"Others/Mermaid_Examples/","title":"Mermaid_Examples","text":"<pre><code>flowchart TD\n    A[User Input] --&gt;|App description,diagram, orGitHub repo| B[Prompt Builder]\n    B --&gt;|threat_model.pymitigations.pyetc.| C{LLM Provider}\n    C --&gt;|OpenAI| D[JSON Response]\n    C --&gt;|Anthropic| D\n    C --&gt;|Google/Mistral/Groq| D\n    C --&gt;|Ollama/LM Studio| D\n    D --&gt; E[Markdown Converter]\n    E --&gt; F[Display Results]\n\n    G[OrganizationalContext] -.-&gt;|Inject here| B\n\n    style G fill:#A855F7,stroke:#9333EA,stroke-width:2px,color:#fff\n    style B fill:#06B6D4,stroke:#0891B2,stroke-width:2px,color:#fff\n</code></pre>"},{"location":"Others/Mermaid_Examples/#current-customization-points","title":"Current Customization Points","text":"<pre><code>graph LR\n    A[threat_model.py] --&gt;|Priority: \u2b50\u2b50\u2b50| B[Add org controls&amp; compliance]\n    C[mitigations.py] --&gt;|Priority: \u2b50\u2b50\u2b50| D[Reference approvedtech stack]\n    E[dread.py] --&gt;|Priority: \u2b50\u2b50| F[Apply orgrisk criteria]\n    G[attack_tree.py] --&gt;|Priority: \u2b50| H[Known attackpatterns]\n    I[test_cases.py] --&gt;|Priority: \u2b50| J[Testing standards]\n\n    style A fill:#D946EF,color:#fff\n    style C fill:#D946EF,color:#fff\n    style E fill:#F59E0B,color:#fff\n    style G fill:#06B6D4,color:#fff\n    style I fill:#06B6D4,color:#fff\n</code></pre>"},{"location":"Others/Mermaid_Examples/#three-approaches-to-using-app","title":"Three Approaches to Using app","text":"<pre><code>graph TD\n    Start{ChooseApproach}\n\n    Start --&gt;|Just testing?Quick PoC?| A1[Approach 1:Use As-Is]\n    Start --&gt;|Ready to deploy?50+ apps?| A2[Approach 2:Fork &amp; Customize]\n    Start --&gt;|Don't want tomodify code?| A3[Approach 3:Wrapper Script]\n\n    A1 --&gt; B1[Manual contextin each description]\n    A2 --&gt; B2[Modify promptsto inject context]\n    A3 --&gt; B3[Script prependscontext automatically]\n\n    B1 --&gt; C1[\u2705 No code changes\u274c Manual work\u274c Inconsistent]\n    B2 --&gt; C2[\u2705 Consistent\u2705 One-time setup\u274c Maintain fork]\n    B3 --&gt; C3[\u2705 No code changes\u274c Extra tooling\u274c Less integrated]\n\n    style A2 fill:#10B981,color:#fff\n    style C2 fill:#10B981,color:#fff\n</code></pre>"},{"location":"Others/Mermaid_Examples/#implementation-roadmap","title":"Implementation Roadmap","text":"<pre><code>graph LR\n    W1[Week 1\u2500\u2500\u2500\u2500\u2500\u2500\u2500Document securitycontrols &amp; standardsDefine data classificationList compliance needs]\n    W2[Week 2\u2500\u2500\u2500\u2500\u2500\u2500\u2500Fork repositoryCreate org_context.pyModify threat_model.py]\n    W3[Week 3\u2500\u2500\u2500\u2500\u2500\u2500\u2500Update other modulesTest with real appsValidate with security team]\n    W4[Week 4+\u2500\u2500\u2500\u2500\u2500\u2500\u2500Deploy internallyTrain teamGather feedback &amp; iterate]\n\n    W1 ==&gt; W2 ==&gt; W3 ==&gt; W4\n\n    style W1 fill:#A855F7,color:#fff\n    style W2 fill:#8B5CF6,color:#fff\n    style W3 fill:#3B82F6,color:#fff\n    style W4 fill:#06B6D4,color:#fff\n</code></pre>"},{"location":"Others/Mermaid_Examples/#impact-of-organizational-context","title":"Impact of Organizational Context","text":"<pre><code>graph LR\n    subgraph \"Without Context\"\n    A1[Generic Input] --&gt; B1[Generic Threat]\n    B1 --&gt; C1[Generic Mitigation]\n    end\n\n    subgraph \"With Org Context\"\n    A2[Same Input +Org Context] --&gt; B2[Specific Threat+ Compliance+ Data Class]\n    B2 --&gt; C2[Approved Controls+ Tech Stack+ Control IDs]\n    end\n\n    style B2 fill:#14B8A6,color:#fff\n    style C2 fill:#14B8A6,color:#fff\n</code></pre>"},{"location":"Others/Mermaid_Examples/#deployment-options","title":"Deployment Options","text":"<pre><code>graph TD\n    Start{ChooseDeployment}\n\n    Start --&gt;|Testing locally| D1[Option 1:Local Streamlit]\n    Start --&gt;|Internal team&lt; 10 users| D2[Option 2:Internal Server]\n    Start --&gt;|Production10-50 users| D3[Option 3:Docker]\n    Start --&gt;|Enterprise50+ users| D4[Option 4:Kubernetes]\n\n    D1 --&gt; E1[streamlit runmain.py]\n    D2 --&gt; E2[Server + reverseproxy + auth]\n    D3 --&gt; E3[Docker container+ env vars]\n    D4 --&gt; E4[K8s deployment+ secrets + LB]\n\n    E2 --&gt; F2[Add: SSO, HTTPS,API key mgmt]\n    E3 --&gt; F3[Add: Secrets,monitoring]\n    E4 --&gt; F4[Add: Autoscaling,HA, monitoring]\n</code></pre>"},{"location":"Others/Project_visuals/","title":"Example_to deploy_nice_pojects_Visualization_&_architecture...","text":""},{"location":"Others/Project_visuals/#presentation-of-diagrams","title":"Presentation of Diagrams","text":""},{"location":"Others/Project_visuals/#plantuml-diagrams","title":"PlantUML Diagrams","text":"<p>(Paste PlantUML code here)</p>"},{"location":"Others/Project_visuals/#graphviz-network-diagram","title":"Graphviz Network Diagram","text":"<p>(Paste Graphviz DOT code here)</p>"},{"location":"Others/Project_visuals/#blockly-flow-diagram","title":"Blockly Flow Diagram","text":"<p>(Paste Blockly code here - optional)</p>"},{"location":"Others/Project_visuals/#prezentacja-mozliwosci-diagramow-i-wykresow","title":"Prezentacja Mo\u017cliwo\u015bci Diagram\u00f3w i Wykres\u00f3w","text":""},{"location":"Others/Project_visuals/#1-mermaid","title":"1. Mermaid","text":""},{"location":"Others/Project_visuals/#diagram-sekwencyjny-sequence-diagram","title":"Diagram Sekwencyjny (Sequence Diagram)","text":"<pre><code>flowchart LR\n    A --&gt; B\n</code></pre> <pre><code>sequenceDiagram\n    participant U\u017cytkownik\n    participant Aplikacja\n    participant Serwer\n    U\u017cytkownik-&gt;&gt;Aplikacja: Wprowadza dane\n    Aplikacja-&gt;&gt;Serwer: Wysy\u0142a zapytanie\n    Serwer--&gt;&gt;Aplikacja: Zwraca wynik\n    Aplikacja-&gt;&gt;U\u017cytkownik: Wy\u015bwietla wynik\n</code></pre> <pre><code>    flowchart LR\n        A[User Input] --&gt;|App description,diagram, orGitHub repo| B[Prompt Builder]\n        B --&gt;|threat_model.pymitigations.pyetc.| C{LLM Provider}\n        C --&gt;|OpenAI| D[JSON Response]\n        C --&gt;|Anthropic| D\n        C --&gt;|Google/Mistral/Groq| D\n        C --&gt;|Ollama/LM Studio| D\n        D --&gt; E[Markdown Converter]\n        E --&gt; F[Display Results]\n\n        G[OrganizationalContext] -.-&gt;|Inject here| B\n\n        style G fill:#A855F7,stroke:#9333EA,stroke-width:2px,color:#fff\n        style B fill:#06B6D4,stroke:#0891B2,stroke-width:2px,color:#fff\n</code></pre>"},{"location":"PLANS/","title":"Plans","text":""},{"location":"PLANS/#my-project-plans-ideas","title":"My project plans &amp; Ideas","text":"<ul> <li>AI_Data_Visualizer improvements (table DF output )</li> <li>Short Crime Story Generator more stories, jokes ..., Others ways of saving stories option to save your story to your data base user must know that thata base stories saved can be view by - app owner,  Add a rating to the story wreaten</li> <li>React applications:</li> <li>Multilingual portfolio website:</li> </ul>"},{"location":"PLANS/#llm-topic-llmmd","title":"LLM TOPIC: LLM.md","text":"<ul> <li>Explore AI on Radeon Today</li> <li>https://www.amd.com/en/products/graphics/radeon-ai.html#tabs-a538c331da-item-3d078efef9-tab</li> <li>RAG</li> <li>https://www.amd.com/en/blogs/2024/how-to-enable-rag-retrieval-augmented-generation-.html</li> </ul>"},{"location":"PLANS/#291125","title":"29.11.25","text":"<ul> <li> <p>app to profile dyficulty fo the lesson from text</p> </li> <li> <p>determining progress of opreation with a slider</p> </li> <li>GPT realtime</li> <li>\"ingenious\" window building ;) possible</li> <li>json + progres build app</li> <li>save your recrutation progres anonymoysly and load whenever you want</li> <li>deploy many documents and tasks APP (any way possible )</li> <li>jupyter LM</li> </ul>"},{"location":"PLANS/#dosument-and-task-blaster","title":"dosument and task blaster","text":""},{"location":"PLANS/#done-plans","title":"done plans","text":"<ul> <li>streamlit applications:</li> <li>AI_Data_Visualizer first version done</li> <li>created and deploy databases PostgreSQL on Ubuntu server for Short Crime Story Generator on https://cloud.digitalocean.com/droplets?i=0c32ac</li> </ul>"},{"location":"SemanticAudioNotes/","title":"SemanticAudioNotes","text":""},{"location":"SemanticAudioNotes/#go-to-the-application","title":"Go to the application","text":""},{"location":"SemanticAudioNotes/#overview","title":"Overview","text":"<p>A Streamlit web application that records or uploads audio notes, transcribes them using OpenAI\u2019s Whisper model, embeds the text with OpenAI embeddings, stores the notes in Qdrant for semantic search, and allows editing, downloading, and searching of notes.</p>"},{"location":"SemanticAudioNotes/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Record audio directly from the browser.</li> <li>Upload existing MP3 files.</li> <li>Transcribe audio to text via OpenAI Whisper.</li> <li>Edit transcribed notes in a text area.</li> <li>Save notes with embeddings into a Qdrant vector database.</li> <li>Perform semantic search on stored notes using embeddings.</li> <li>Download notes as MP3 or TXT files.</li> </ul>"},{"location":"SemanticAudioNotes/#technologies-skills","title":"Technologies &amp; skills","text":"<ul> <li>Python  </li> <li>Streamlit  </li> <li>audiorecorder (web recording)  </li> <li>OpenAI API (Whisper, Embeddings)  </li> <li>Qdrant vector database  </li> <li>dotenv for environment variables  </li> <li>hashlib md5 for audio change detection  </li> <li>st_paywall for authentication  </li> <li>Custom modules: <code>my_package.tips</code>, <code>api_key_loader_zmiany</code> </li> </ul>"},{"location":"SemanticAudioNotes/#project-report","title":"Project Report","text":"<ul> <li>Utilizes Streamlit session state to persist audio and text across interactions.</li> <li>MD5 hashing detects changes in recorded audio to reset transcriptions.</li> <li>Caches OpenAI and Qdrant clients for efficient reuse.</li> <li>Ensures the Qdrant collection exists before inserting notes.</li> <li>Supports both real-time recording and file upload workflows.</li> </ul>"},{"location":"SemanticAudioNotes/#sample-photos","title":"Sample photos","text":"\u0141adowanie pliku Transkrypcja"},{"location":"SemanticAudioNotes/#application-usage","title":"Application usage","text":"<ul> <li>Open the Streamlit app in a browser.  </li> <li>Navigate to the \u201cDodaj notatk\u0119\u201d tab to record a new audio note or to the \u201cWczytaj nagranie z pliku mp3\u201d tab to upload an existing MP3.  </li> <li>Click Transkrybuj to convert the audio into text.  </li> <li>Edit the transcribed text if needed, then click Wy\u015blij notatk\u0119 do twojej bazy wektorowej QDRANT to store it.  </li> <li>Use the \u201cWyszukaj notatk\u0119 w chmurze\u201d tab to perform a semantic search by entering a query; relevant notes and similarity scores will appear.</li> </ul>"},{"location":"SemanticAudioNotes/#where-to-get-api-key-and-addresses","title":"Where to get API key and addresses?","text":"<ol> <li>OpenAI API Key (openai_api_key): </li> <li>Visit the OpenAI API Keys page.  </li> <li>Log in to your account or create a new one.  </li> <li> <p>Click \"Create API key\" and copy the key.</p> </li> <li> <p>QuDant keys and URL: </p> </li> <li>QDRANT_URL: The address of your QuDant server, e.g., <code>https://your-qdrant-instance.com</code>.  </li> <li>QDRANT_API_KEY: The QuDant API key (if required).  </li> <li>More details can be found in the QuDant documentation.</li> </ol>"},{"location":"SemanticAudioNotes/#example-configuration-file","title":"Example configuration file:","text":"<pre><code>OPENAI_API_KEY=your-openai-api-key\nQDRANT_URL=https://your-qdrant-instance.com\nQDRANT_API_KEY=your-qdrant-api-key\nReplace your-openai-api-key, https://your-qdrant-instance.com and your-qdrant-api-key with your own values.\n</code></pre>"},{"location":"SemanticAudioNotes/#go-to-the-application_1","title":"Go to the application","text":""},{"location":"Watch_YouTube_Videos%E2%80%93No_Ads/","title":"\ud83c\udfa5 Watch YouTube Videos - No Ads","text":"<p>Go to the application</p>"},{"location":"Watch_YouTube_Videos%E2%80%93No_Ads/#watch-youtube-videos-no-ads","title":"Watch YouTube Videos (No Ads)","text":""},{"location":"Watch_YouTube_Videos%E2%80%93No_Ads/#overview","title":"Overview","text":"<p>A lightweight Streamlit app that allows users to watch YouTube videos without ads by embedding them directly in a clean, ad-free interface.</p>"},{"location":"Watch_YouTube_Videos%E2%80%93No_Ads/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Accepts YouTube URLs `youtube.com'</li> <li>Extracts video ID automatically</li> <li>Embeds video in an iframe with autoplay enabled</li> <li>Validates input to ensure only valid YouTube links are processed</li> <li>Displays video in a responsive, centered layout with clean UI</li> <li>Nev wersion whit double screen to watch your faworite contents</li> </ul>"},{"location":"Watch_YouTube_Videos%E2%80%93No_Ads/#technologies-skills","title":"Technologies &amp; skills","text":"<ul> <li>Python</li> <li>Streamlit</li> <li>HTML/iframe embedding</li> <li>URL parsing and string manipulation</li> </ul>"},{"location":"Watch_YouTube_Videos%E2%80%93No_Ads/#application-usage","title":"Application usage","text":"<ul> <li>Paste any YouTube video URL</li> <li>Click \"Enter\" or wait for auto-detection</li> <li>Video plays instantly in the embedded player without ads</li> <li>No downloads, no installations, no registration required</li> </ul> <p>Go to the application</p>"},{"location":"ds_toolbox/","title":"ds_toolbox","text":""},{"location":"ds_toolbox/#go-to-the-application","title":"Go to the application","text":""},{"location":"ds_toolbox/#overview","title":"Overview","text":"<p>A Streamlit data\u2011science toolbox that lets users upload CSV/Excel files, clean missing values and outliers, visualize data with various plots, and train a regression model.</p>"},{"location":"ds_toolbox/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Upload CSV/Excel file via the Streamlit uploader.  </li> <li>Data cleaning: impute missing values (mean, median, mode) and remove IQR outliers.  </li> <li>Interactive visualisation: histogram, boxplot, scatter plot, heatmap using Plotly.  </li> <li>Train a regression model with automatic evaluation metrics.</li> </ul>"},{"location":"ds_toolbox/#technologies-skills","title":"Technologies &amp; skills","text":"<ul> <li>Python  </li> <li>Streamlit  </li> <li>Pandas  </li> <li>Plotly  </li> <li>Scikit\u2011learn  </li> </ul>"},{"location":"ds_toolbox/#project-report","title":"Project Report","text":"<ul> <li>Modular component architecture (data_loader, data_cleaner, visualizer, model_trainer).  </li> <li>Data ingestion and preprocessing pipeline.  </li> <li>Interactive charts rendered with Plotly in Streamlit.  </li> <li>Simple regression training routine returning metrics.</li> </ul>"},{"location":"ds_toolbox/#sample-photos","title":"Sample photos","text":""},{"location":"ds_toolbox/#application-usage","title":"Application usage","text":"<ul> <li>Upload a CSV or Excel file.  </li> <li>Use the \u201cData Cleaning\u201d expander to impute missing values and remove outliers.  </li> <li>Select visualisation type in the \u201cVisualisation\u201d section and view interactive charts.  </li> <li>Choose target column in the \u201cModeling (Regression)\u201d section, run training, and review metrics.</li> </ul> <p>Write an HTML anchor tag that: - uses class=\"md-button md-button--primary\" - has the text \u201cGo to the application\u201d - keeps everything else exactly as shown below - only replaces the href value with  from README.md. </p>"},{"location":"ds_toolbox/#go-to-the-application_1","title":"Go to the application","text":""},{"location":"iris/","title":"Analiza Danych EDA Irys\u00f3w: Eksploracja Domenowa","text":""},{"location":"iris/#analiza-danych-eda-irysow-eksploracja-domenowa","title":"Analiza Danych EDA Irys\u00f3w: Eksploracja Domenowa","text":"<p>Zapraszamy do zapoznania si\u0119 z wyj\u0105tkowym projektem autorstwa Rafa\u0142a, kt\u00f3ry przenosi nas w \u015bwiat analizy danych irys\u00f3w za pomoc\u0105 eksploracji domenowej (EDA). W tym projekcie znajdziesz mn\u00f3stwo trafnych wniosk\u00f3w i ciekawych obserwacji, kt\u00f3re rzucaj\u0105 nowe \u015bwiat\u0142o na te pi\u0119kne kwiaty. Przygotuj si\u0119 na fascynuj\u0105c\u0105 podr\u00f3\u017c przez dane, kt\u00f3ra z pewno\u015bci\u0105 wzbogaci Twoj\u0105 wiedz\u0119 i zainspiruje do dalszych bada\u0144.</p> <p>Pobierz Notebook</p> <p></p>"},{"location":"titanic/","title":"Analiza Danych EDA Tytanika: Eksploracja Domenowa","text":""},{"location":"titanic/#analiza-danych-eda-tytanika-eksploracja-domenowa","title":"Analiza Danych EDA Tytanika: Eksploracja Domenowa","text":"<p>Pobierz Notebook</p> <p></p>"},{"location":"welcome_survey_clustering_pipeline/","title":"Welcome Survey Clustering App pipeline","text":"<p>Go to the application</p> <p>Project start: Not specified</p>"},{"location":"welcome_survey_clustering_pipeline/#overview","title":"Overview","text":"<p>The Welcome Survey Clustering App is a Streamlit application that uses clustering to group participants based on their survey responses. It provides insights into the characteristics of different groups and allows users to find people with similar interests.</p>"},{"location":"welcome_survey_clustering_pipeline/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Load translations from JSON files for multilingual support.</li> <li>Allow users to switch between English and Polish languages.</li> <li>Collect user input through a sidebar form, including age, education level, favorite animals, favorite place, and gender.</li> <li>Predict the cluster ID for the user based on their responses using a pre-trained clustering model.</li> <li>Display the predicted cluster's name and description.</li> <li>Show summary statistics of total participants and those in the user's group.</li> <li>Visualize categorical distributions (age, education level, favorite animals, favorite place, gender) within the user's group using pie charts.</li> </ul>"},{"location":"welcome_survey_clustering_pipeline/#technologies-skills","title":"Technologies &amp; skills","text":"<ul> <li>Python</li> <li>Streamlit</li> <li>Pandas</li> <li>PyCaret for clustering</li> <li>Plotly Express for data visualization</li> </ul>"},{"location":"welcome_survey_clustering_pipeline/#project-report","title":"Project Report","text":"<ul> <li>The app uses a pre-trained clustering model to categorize participants based on their survey responses.</li> <li>It supports multilingualism by loading translations from JSON files.</li> <li>User inputs are collected through a sidebar form, and the app predicts the user's cluster ID using the clustering model.</li> <li>The app provides visualizations of categorical distributions within the user's group.</li> </ul>"},{"location":"welcome_survey_clustering_pipeline/#sample-photos","title":"Sample photos","text":"Pic_1 Pic_2 Pic_3 <p>Application usage - Users can switch between English and Polish languages. - They fill out a form with their age, education level, favorite animals, favorite place, and gender. - The app predicts the user's cluster ID and displays the cluster's name and description. - Users can see summary statistics and visualizations of categorical distributions within their group.</p> <p>Go to the application</p>"}]}